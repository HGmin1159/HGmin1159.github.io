---
title: \[Basic Dimension Reduction\] Part4. Advanced PCA
categories: [Dimension]
tags: [차원 축소,Dimension reduction]
excerpt: PCA의 응용 기법에 대한 설명
sidebar:
  - title: "Dimensionality Reduction"
    image: /assets/img/dimension.png
    image_alt: "image"
    nav: Dimension
author_profile: False
---


## 0. 개요

 Matrix Factorization은 행렬을 주요 요인으로 분해한다는 개념으로, 천문학,화학,자연어 처리, 사운드 분석, 추천 시스템 등에서 다양하게 응용되는 개념이라고 한다. 

 앞서 포스팅한 PCA나 군집분석과는 다르게, 이번에는 좀 더 일반화된 개념부터 접근해서 행렬 분해의 전반을 공부 해보려고 한다. 

 현재까지 예정되어 있는 학습 내용은 다음과 같다. 

Part 1. Bregmann Divergence

Part 2.Generalized Non Negative Matrix Factorizaion with Bregamnn Divergence

Part 3. Independent Component Analysis

Part 4. Incremental PCA, Kernel PCA, Sparse PCA

Part 5. Factorization Model

***



## 1. PCA란?

PCA는 가장 기본적이면서도 보편적인 행렬분해라고 말할 수 있는 기법으로 SLC를 기반으로 한 변수 추출법 중 가장 많은 분산을 가지는 축을 찾는 방법이다. 

PCA의 특징은 다음과 같다.

- 분산=정보량이라는 기준으로 분해가 이뤄짐
- 결과물의 축들이 서로 직교하므로 선형적인 정보를 저장하는데에 특화
- 결과물 축들의 이름이 사라지므로 추가적인 분석이 필요



 PCA는 기본적인 방법인 만큼 다음과 같은 단점들을 안고 있다.

- $O(p^2n + p^3)$의 시간 복잡도를 가지므로 빅데이터에 비교적 취약
- 오직 선형적인 정보만을 저장하므로 비선형을 잡아내지 못함
- 모든 인풋 변수들을 사용해서 만들어내므로 $p >> n$일시 분석이 불가

그러나 PCA는 1920년대에 나온 방법인 만큼 위의 단점을 해결하는 여러가지 응용 기법들이 있다. 이번포스팅에서는 그에 대해서 다뤄보려고 한다. 그러나 각각의 기법이 많은 수학적 지식을 필요로 하므로 이번에도 컨셉 정도만 소개하는 데에 그치지 싶다. 



## 2. Kernel PCA

Kernel PCA는 선형적 정보만을 뽑아낸다는 PCA의 단점을 해결하기 위해 개발된 기법이다. 

기존 디자인 매트릭스 X를 변환(Transfrom)시키면 비선형에 대응할 수 있지만, 그만큼 계산량이 기하급수적으로 늘어나는 단점이 있다. Kernel PCA는 Kernel Trick을 사용해서 이러한 계산량을 극적으로 줄일 수 있다. 

이에 대해서는 다른 포스팅을 통해 좀 더 자세히 다뤄보려고 한다. 

[Kernel Trick 링크](https://hgmin1159.github.io/dimension/kernel-method/)

## 3. Sparse PCA

Sparse PCA는 피쳐가 매우 많은 자료에 대해서 사용할 수 있는 PCA기법이다. 기본적인 컨셉은 전체 피쳐를 사용하는 것이 아니라, 중요하다고 생각되는 피쳐에 대해서만 PCA를 해주는 기법이라고 한다. 

특히 Sparse PCA가 중요한 이유는 현대에 가장 빈번하게 등장하는 문제 중 하나인 $N<<P$의 문제에 대응을 할 수 있다는 점이다. 

이에 대해서도 다른 포스팅을 통해 좀 더 자세히 다뤄보겠다. 



## 4. Incremental PCA

PCA를 할때 데이터가 너무 크다면 연산량이 클 뿐만 아니라 연산 할때 메모리에 올리는 데이터 량도 방대해져서 연산이 불가해질 수 있다. 

Incremental PCA는 이러한 PCA의 단점에 대응하기 위해 개발된 기법이다. Incremental PCA는 모든 데이터를 한번에 분석하는 것이 아니라 Batch Size만큼 조금씩 분석해가며 목표로 하는 Singular Vector를 찾아낸다. 

아쉽게도 Incremental PCA에 대해서 설명하고 있는 완성도 높은 논문을 찾지 못했다. 이에 대해서는 다음에 좀 더 공부 해서 포스팅을 해보도록 하겠다. 



***

처음에는 간단하게 생각했으나 방식 하나하나가 생각보다 시간 투자가 많이 필요한 방법들이었다. 체감상 이전에 포스팅 했던 NMF나 ICA보다도 더 분량이 많았다. 

그래도 하나 하나가 수학적,통계적 기법들이 많이 들어간 방법들이므로, 하나를 공부하면 차원축소가 아닌 다른 기법에도 적용을 할 수 있다. 따라서 긴 호흡으로 천천히 공부를 해봐야겠다. 

